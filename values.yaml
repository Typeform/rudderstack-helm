# Default values for rudderstack.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.


# Deployment specific values for rudderstack.
# Following values must be filled in for the deployment to succeed

# Please uncomment below lines and fill values accordingly.
# Please enter api token obtained from rudder dashboard below
# rudderWorkspaceToken:

ingress:
  enabled: true
  annotations:
    # kubernetes.io/ingress.class: alb
    kubernetes.io/ingress.class: gce
    # kubernetes.io/tls-acme: "true"
  # If tls support required, create a secret with cert and key
  # Refer: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

global:
  # backendReplicaCount decides the replica count for rudder backend and postgresql containers
  backendReplicaCount: 2
  imagePullSecrets: []
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  storageClass: ""

backend:
  image:
    repository: rudderlabs/rudder-server
    version: v0.1.3
    pullPolicy: Always
  service:
    type: NodePort
    port: 8080
  resources:
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    #requests:
      # cpu: 100m
      # memory: 2048Mi
  resources:
    requests:
      memory: 2560Mi
    limits:
      memory: 5120Mi

  nodeSelector: {}

  persistence:
    mountPath: /data/rudderstack
    accessModes:
      - ReadWriteOnce
    size: 36Gi
    annotations: {}
  tolerations: []

  config:
    mountPath: "/etc/rudderstack"

  extraEnvVars:
    - name: CONFIG_BACKEND_URL
      value: "https://api.rudderlabs.com"
    - name: CONFIG_PATH
      value: "/etc/rudderstack/config.toml"
    - name: AWS_ACCESS_KEY_ID
      value: "Add your aws key id here"
    - name: AWS_SECRET_ACCESS_KEY
      value: "Add your aws access secret here"
    - name: BUGSNAG_KEY
      value: "3669852453c688bb50a0a2d27bf0ee58"
    - name: RUDDER_TMPDIR
      value: "/data/rudderstack"
    - name: JOBS_BACKUP_STORAGE_PROVIDER
      value: "GCS" # object storage provider to store backups eg. S3, AZURE_BLOB, MINIO
    - name: JOBS_BACKUP_BUCKET
      value: "Add your bucket name to store backups of incoming events"
    - name: JOB_STATUS_BACKUP_BUCKET
      value: "Add your bucket name to store backups of status of incoming events"
    - name: GOOGLE_APPLICATION_CREDENTIALS
      value: "/etc/rudderstack/google-application-credentials.json"
    - name: LOG_LEVEL
      value: "INFO" # eg. DEBUG, ERROR
    - name: INSTANCE_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name

transformer:
  replicaCount: 1
  service:
    port: 9090
  image:
    repository: rudderlabs/rudder-transformer
    version: latest
    pullPolicy: Always
  resources:
    requests:
      memory: 256Mi
    limits:
      memory: 768Mi

postgresql:
  nameOverride: "rudderstack-postgresql"
  postgresqlUsername: rudder
  postgresqlPassword: password
  postgresqlDatabase: jobsdb
  postgresqlRunAsUser: 70
  imagePullPolicy: IfNotPresent
  image:
    repository: postgres
    tag: "11-alpine"
    pullPolicy: IfNotPresent
  persistence:
    size: 100Gi
  replication:
    enabled: false
  service:
    type: "ClusterIP"
    port: 5432
  resources:
    requests:
      memory: 2048Mi
    limits:
      memory: 4096Mi

telegraf_sidecar:
  enabled: true
  nameOverride: "rudderstack"
  image:
    repo: "telegraf"
    tag: "1.12-alpine"
    pullPolicy: IfNotPresent
  resources:
    requests:
      memory: 128Mi
      cpu: 100m
    limits:
      memory: 128Mi
      cpu: 100m
  config:
    mountPath: /etc/telegraf
    agent:
      interval: "10s"
      round_interval: true
      metric_batch_size: 1000
      metric_buffer_limit: 10000
      collection_jitter: "0s"
      flush_interval: "10s"
      flush_jitter: "0s"
      precision: ""
      debug: false
      quiet: false
      logfile: ""
      hostname: "$HOSTNAME"
      omit_hostname: false
    processors:
      - enum:
          mapping:
            field: "status"
            dest: "status_code"
            value_mappings:
              healthy: 1
              problem: 2
              critical: 3
    outputs:
      - health:
          service_address: "http://:8888"
          compares:
            field: buffer_size
            lt: 5000.0
          contains:
            field: buffer_size
      - influxdb:
          urls:
            - "http://influxdb.monitoring.svc:8086"
          database: "telegraf"
    inputs:
      - statsd:
          service_address: ":8125"
          percentiles:
            - 50
            - 90
            - 95
            - 99
          metric_separator: "_"
          allowed_pending_messages: 10000
          percentile_limit: 100

affinity: {}
